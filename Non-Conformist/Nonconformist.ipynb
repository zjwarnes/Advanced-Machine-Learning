{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nonconformist as nc\n",
    "\n",
    "import pyodbc\n",
    "\n",
    "db = \"UCM\"\n",
    "table = \"[dbo].[student_course_matrix]\"\n",
    "\n",
    "query = \"SELECT [Student ID], [COR1003], [COR1004], [COR1002] FROM \" + db + \".\" + table\n",
    "\n",
    "conn = pyodbc.connect(\n",
    "    'Driver={SQL Server};'\n",
    "    'Server=DESKTOP-8LSE8HT;'\n",
    "    'Database=UCM;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df = pd.DataFrame(df, columns = df.columns)\n",
    "df = df.drop('Student ID', axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from nonconformist.base import RegressorAdapter\n",
    "from nonconformist.icp import IcpRegressor\n",
    "from nonconformist.nc import RegressorNc\n",
    "from nonconformist.acp import AggregatedCp\n",
    "from nonconformist.acp import RandomSubSampler, BootstrapSampler, CrossSampler\n",
    "from nonconformist.evaluation import reg_mean_errors\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Experiment setup\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "course = 'COR1002'\n",
    "# The target variable is 'quality'.\n",
    "Y = df[course]\n",
    "X =  df.drop(course, axis = 1)\n",
    "# Split the data into train and test data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "# Build the model with the random forest regression algorithm:\n",
    "truth = Y_test\n",
    "\n",
    "idx = np.random.permutation(len(df))\n",
    "train = idx[:int(2 * idx.size / 3)]\n",
    "test = idx[int(2 * idx.size / 3):]\n",
    "\n",
    "truth = df[course]\n",
    "columns = df.columns #['min', 'max', 'truth']\n",
    "significance = 0.95\n",
    "\n",
    "train_x = X.loc[train,:].to_numpy()\n",
    "train_y = Y.loc[train].to_numpy()\n",
    "\n",
    "test_x = X.loc[test,:].to_numpy()\n",
    "test_y = Y.loc[test].to_numpy()\n",
    "truth = test_y\n",
    "\n",
    "x,y = train_x, train_y\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Define models\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "models = {  \n",
    "    'ACP-RandomSubSampler'  : \n",
    "        AggregatedCp(\n",
    "            IcpRegressor(\n",
    "                RegressorNc(\n",
    "                    RegressorAdapter(DecisionTreeRegressor()))),\n",
    "                        RandomSubSampler()),\n",
    "    'ACP-CrossSampler'      : \n",
    "        AggregatedCp(\n",
    "            IcpRegressor(\n",
    "                RegressorNc(\n",
    "                    RegressorAdapter(DecisionTreeRegressor()))),\n",
    "                        CrossSampler()),\n",
    "    'ACP-BootstrapSampler'  : \n",
    "        AggregatedCp(\n",
    "            IcpRegressor(\n",
    "                RegressorNc(\n",
    "                    RegressorAdapter(DecisionTreeRegressor()))),\n",
    "                        BootstrapSampler())\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train, predict and evaluate\n",
    "# -----------------------------------------------------------------------------\n",
    "for name, model in models.items():\n",
    "    model.fit(train_x, train_y)\n",
    "    prediction = model.predict(test_x)\n",
    "    prediction_sign = model.predict(test_x,\n",
    "                                    significance=significance)\n",
    "    table = np.vstack((prediction_sign.T, truth)).T\n",
    "    df = pd.DataFrame(table, columns=columns)\n",
    "    print('\\n{}'.format(name))\n",
    "    print('Error rate: {}'.format(reg_mean_errors(prediction,\n",
    "                                                  truth,\n",
    "                                                  significance)))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.icp import IcpClassifier\n",
    "from nonconformist.nc import ClassifierNc\n",
    "\n",
    "\n",
    "\n",
    "course = 'COR1002'\n",
    "# The target variable is 'quality'.\n",
    "Y = df[course]\n",
    "X =  df.drop(course, axis = 1)\n",
    "# Split the data into train and test data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "# Build the model with the random forest regression algorithm:\n",
    "truth = Y_test\n",
    "\n",
    "idx = np.random.permutation(len(df))\n",
    "train = idx[:int(2 * idx.size / 3)]\n",
    "test = idx[int(2 * idx.size / 3):]\n",
    "\n",
    "truth = df[course]\n",
    "columns = df.columns #['min', 'max', 'truth']\n",
    "significance = 0.95\n",
    "\n",
    "train_x = X.loc[train,:].to_numpy()\n",
    "train_y = Y.loc[train].to_numpy()\n",
    "\n",
    "test_x = X.loc[test,:].to_numpy()\n",
    "test_y = Y.loc[test].to_numpy()\n",
    "truth = test_y\n",
    "\n",
    "x,y = train_x, train_y\n",
    "# Test data\n",
    "#data = load_iris()\n",
    "#x, y = data.data, data.target\n",
    "\n",
    "for i, y_ in enumerate(np.unique(y)):\n",
    "    y[y == y_] = i\n",
    "\n",
    "n_instances = y.size\n",
    "idx = np.random.permutation(n_instances)\n",
    "\n",
    "train_idx = idx[:int(n_instances / 3)]\n",
    "cal_idx = idx[int(n_instances / 3):2 * int(n_instances / 3)]\n",
    "test_idx = idx[2 * int(n_instances / 3):]\n",
    "\n",
    "nc = ClassifierNc(ClassifierAdapter(RandomForestClassifier()))\n",
    "icp = IcpClassifier(nc)\n",
    "\n",
    "icp.fit(x[train_idx, :], y[train_idx])\n",
    "icp.calibrate(x[cal_idx, :], y[cal_idx])\n",
    "\n",
    "\n",
    "print(pd.DataFrame(icp.predict_conf(x[test_idx, :]), columns=['Label', 'Confidence', 'Credibility']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Authors: Henrik Linusson\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.icp import IcpClassifier\n",
    "from nonconformist.nc import ClassifierNc, MarginErrFunc\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Setup training, calibration and test indices\n",
    "# -----------------------------------------------------------------------------\n",
    "data = load_iris()\n",
    "\n",
    "idx = np.random.permutation(data.target.size)\n",
    "train = idx[:int(idx.size / 3)]\n",
    "calibrate = idx[int(idx.size / 3):int(2 * idx.size / 3)]\n",
    "test = idx[int(2 * idx.size / 3):]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train and calibrate\n",
    "# -----------------------------------------------------------------------------\n",
    "icp = IcpClassifier(ClassifierNc(ClassifierAdapter(DecisionTreeClassifier()),\n",
    "                                 MarginErrFunc()))\n",
    "icp.fit(data.data[train, :], data.target[train])\n",
    "icp.calibrate(data.data[calibrate, :], data.target[calibrate])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Predict\n",
    "# -----------------------------------------------------------------------------\n",
    "prediction = icp.predict(data.data[test, :], significance=0.9)\n",
    "header = np.array(['c0','c1','c2','Truth'])\n",
    "table = np.vstack([prediction.T, data.target[test]]).T\n",
    "df = pd.DataFrame(np.vstack([header, table]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from nonconformist.base import RegressorAdapter\n",
    "from nonconformist.icp import IcpRegressor\n",
    "from nonconformist.nc import RegressorNc, AbsErrorErrFunc, RegressorNormalizer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Setup training, calibration and test indices\n",
    "# -----------------------------------------------------------------------------\n",
    "course = 'COR1002'\n",
    "# The target variable is 'quality'.\n",
    "Y = df[course]\n",
    "X =  df.drop(course, axis = 1)\n",
    "# Split the data into train and test data:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "# Build the model with the random forest regression algorithm:\n",
    "truth = Y_test\n",
    "\n",
    "idx = np.random.permutation(len(df))\n",
    "train = idx[:int(2 * idx.size / 3)]\n",
    "test = idx[int(2 * idx.size / 3):]\n",
    "\n",
    "truth = df[course]\n",
    "columns = df.columns #['min', 'max', 'truth']\n",
    "significance = 0.95\n",
    "\n",
    "train_x = X.loc[train,:].to_numpy()\n",
    "train_y = Y.loc[train].to_numpy()\n",
    "\n",
    "test_x = X.loc[test,:].to_numpy()\n",
    "test_y = Y.loc[test].to_numpy()\n",
    "truth = test_y\n",
    "\n",
    "\n",
    "idx = np.random.permutation(Y.size)\n",
    "train = idx[:int(idx.size / 3)]\n",
    "calibrate = idx[int(idx.size / 3):int(2 * idx.size / 3)]\n",
    "test = idx[int(2 * idx.size / 3):]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Without normalization\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train and calibrate\n",
    "# -----------------------------------------------------------------------------\n",
    "underlying_model = RegressorAdapter(DecisionTreeRegressor(min_samples_leaf=5))\n",
    "nc = RegressorNc(underlying_model, AbsErrorErrFunc())\n",
    "icp = IcpRegressor(nc)\n",
    "icp.fit(X[train, :], Y[train])\n",
    "icp.calibrate(X[calibrate, :], Y[calibrate])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Predict\n",
    "# -----------------------------------------------------------------------------\n",
    "prediction = icp.predict(X[test, :], significance=0.1)\n",
    "header = ['min','max','truth','size']\n",
    "size = prediction[:, 1] - prediction[:, 0]\n",
    "table = np.vstack([prediction.T, Y[test], size.T]).T\n",
    "df = pd.DataFrame(table, columns=header)\n",
    "print(df)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# With normalization\n",
    "# -----------------------------------------------------------------------------\n",
    "# Train and calibrate\n",
    "# -----------------------------------------------------------------------------\n",
    "underlying_model = RegressorAdapter(DecisionTreeRegressor(min_samples_leaf=5))\n",
    "normalizing_model = RegressorAdapter(KNeighborsRegressor(n_neighbors=1))\n",
    "normalizer = RegressorNormalizer(underlying_model, normalizing_model, AbsErrorErrFunc())\n",
    "nc = RegressorNc(underlying_model, AbsErrorErrFunc(), normalizer)\n",
    "icp = IcpRegressor(nc)\n",
    "icp.fit(X[train, :], Y[train])\n",
    "icp.calibrate(X[calibrate, :], Y[calibrate])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Predict\n",
    "# -----------------------------------------------------------------------------\n",
    "prediction = icp.predict(Y[test, :], significance=0.9)\n",
    "header = ['min','max','truth','size']\n",
    "size = prediction[:, 1] - prediction[:, 0]\n",
    "table = np.vstack([prediction.T, Y[test], size.T]).T\n",
    "df = pd.DataFrame(table, columns=header)\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}